import json
import sys
import pickle 
from src.elt import *
from src.make_dataset import *
from src.build_features import *
from src.model import *
from src.multi_kernel import *



def main_func(**kwargs):
    name_path = kwargs['outpath']
    if name_path[0] == 'data':
        main_scrape(name_path, kwargs)
    
    #Get paths of all Malware apps
    malware_path, type_of_malware = malware_app_paths() 
    
    #get paths of all newly created benign apps   
    benign_paths = benign_app_paths_test(name_path[0]) 
    malware_apps = malware_path[:len(benign_paths)]
    path = benign_paths[:2] + malware_apps
   
          
    #Clean all smali files and extract diffrent structures to construct the matrix 
    print('Creating data structure for train data')
    print('------------------------------------')
    apps_dic,code_block_dic,package_dic = clean_data(path)
    
    ## Gets all the unique API's in the data structure
    api_list_inter, app_list = unique_api_apps(apps_dic)
    
    
    ## Creates an intermediate A structure to find the count of each API
    print('creating intermediate A structure ')
    print('------------------------------------')
    a_matrix_inter = create_a_matrix\
    (app_list,api_list_inter, apps_dic)
    print('------------------------------------')
    
    ## Gets the index of all API's that occur less in less then n apps
    extra_api_list = get_index_of_api\
    (a_matrix_inter,api_list_inter,2)
    
     ## removes all the API's from the 3 data structures
    apps_dic,code_block_dic,package_dic = remove_apis\
    (extra_api_list,apps_dic,code_block_dic,package_dic)
    
    ## Gets the new list of unique API's
    api_list, app_list = unique_api_apps(apps_dic)

    ## Saves these datastructures again 
    save_structures(apps_dic,code_block_dic,package_dic,name_path )
    
    ## Saves unique api_list
    print(len(api_list))
    api_path = name_path[0] + '/processed/unique_api.text'
    with open(api_path, "wb") as fp: 
        pickle.dump(api_list, fp)
        
    
    ## Creates A matrix
    a_matrix = create_a_matrix(app_list,api_list,apps_dic)
    print('------------------------------------')
    ## Creatres B matrix
    b_matrix = create_b_matrix(code_block_dic,api_list,)
    print('------------------------------------')

    ## Creates P matrix 
    p_matrix = create_p_matrix(package_dic,api_list)
    print('------------------------------------')

    ## Saves all the 3 matrices 
    name_list = [name_path[0], 'a_matrix','b_matrix','p_matrix']
    save_features(a_matrix,b_matrix,p_matrix, name_list)


    ## Gets path to all benign apps
    test_benign_paths =  benign_paths[2:4]

    ## Gets path to all malware apps
    malware_apps = []
    for i in malware_path:
        if i.split('/')[-1] not in app_list:
            malware_apps.append(i)

    malware_test_paths = malware_apps[2:4]

    ## Gets all the paths 
    
    test_paths = test_benign_paths + malware_test_paths
 

    ## Creates structure for the test set 
    print('creating data structure for test set')
    test_apps_dic = get_data_test(test_paths)
    print('------------------------------------')

    ## saves the new test structure created 
    test_name_list = [name_path[0], 'test_app_api.json']
    test_save_structures(test_apps_dic, test_name_list)
    
    # gets list of app names
    app_list_test = list(test_apps_dic.keys())
    
    ## Creates the A matrix for the test set 
    a_test_matrix = create_a_matrix_test(app_list_test,api_list,test_apps_dic)
    path_a_test = name_path[0] + '/matrix/' + 'a_test_matrix.npz'
    save_npz(path_a_test, a_test_matrix)

    #Initilaze our linear SVC model
    clf = LinearSVC(max_iter = 10000)
    
    #loop through all the diffrent kernels
    kernel_list = ['A.A^T','A.B.A^T', 'A.P.A^T','A.B.P.A^T']
    
    #get the scores for all the kernels
    scores_df,train_kernel_list, test_kernel_list, labels = get_scores(a_test_matrix,a_matrix, b_matrix, \
                           p_matrix, kernel_list, clf, \
                          benign_paths,app_list,app_list_test,\
                          name_path)
    
    #chose model to learn wieghts
    model_align = Alignf(typ="convex")    
    #create multi kernel for train and test
    df_train_multi, df_test_multi =         get_scores_multi(train_kernel_list,test_kernel_list, linear_kernel, \
                    model_align, labels, benign_paths,app_list, app_list_test)
    print(scores_df)
    #get accuracy score for multik-kernel model
    dic_scores = {}
    dic_scores['multi_kernel'],test_df = run_model(df_train_multi,df_test_multi, clf)
    print(dic_scores)

        
    #save it as a CSV 
    result_path = 'results/'
    if not os.path.isdir(result_path):
        os.mkdir(result_path)
    scrores_path = result_path + '/'+ name_path[4]
    scores_df.to_csv(scrores_path)
    
if __name__=='__main__':
    warnings.filterwarnings("ignore")
    if len(sys.argv) > 1:
        if sys.argv[1] == 'test':
            with open('config/test-params.json') as file:
                cfg = json.load(file)
    else: 
        with open('config/params.json') as file:
            cfg = json.load(file)
        
    main_func(**cfg)




