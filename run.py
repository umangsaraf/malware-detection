import json
import sys
import pickle 
from src.elt import *
from src.make_dataset import *
from src.build_features import *
from src.model import *



def main_func(**kwargs):
    name_path = kwargs['outpath']
    if name_path[0] == 'data':
        #To track all scraped xml files
        gz_list = []
        #Keep track of scraped apps
        scraped_apps = [] 
        #Keeps track of all apk_files
        apk_files = []
        # returns all links
        all_links = get_all_links() 


        i = 0
        np.random.seed(44)
        print('downloading APKs')
        pbar = tqdm(total = kwargs['total_links'])
        #runs till we collect the number of files needed
        while i < kwargs['total_links']: 
            #randomly choses a gz url
            gz_link = np.random.choice(all_links) 
            #checks if we have already scraped it 
            if gz_link not in gz_list: 
                #adds the gz url to scraped gz list
                gz_list.append(gz_link)  
                #Downoads the gz files and write is as an xml
                xml = get_xml(gz_link) 
                #grabs all the links to app's Apk's
                links = get_links_from_xml(xml) 
                j = 0
                while j < kwargs['Link_in_each_cat']:
                    #randomly choses a link to app's apk
                    apk_links = np.random.choice(links) 
                    #to check if we havent already scraped it 
                    if apk_links not in scraped_apps: 
                        #dowloads APK 
                        apk_file_name = create_apk(apk_links,name_path[0]) 
                        if apk_file_name == False:
                            break 
                        apk_files.append(apk_file_name)
                        scraped_apps.append(apk_links)  
                        i = i+1
                        j = j+1
                        pbar.update(1)

        pbar.close()
        print('output saved to /' + name_path[0]+ '/apk')
        print('decompiling APK files into smali code')
        #Decompile all Benign APK files into smali code
        for apk_ in tqdm(apk_files):
            get_smalli(name_path[0], apk_)
        print('output saved to /'+ name_path[0]+ '/smali')
    
          
    #Get paths of all Malware apps
    malware_path, type_of_malware = malware_app_paths() 
    
    #get paths of all newly created benign apps    
    benign_paths = benign_app_paths_test(name_path[0]) 
    malware_apps = malware_path[:len(benign_paths)]
    path = benign_paths[:2] + malware_apps
   
          
    #Clean all smali files and extract diffrent structures to construct the matrix 
    print('Creating data structure for test data')
    print('------------------------------------')
    apps_dic,code_block_dic,package_dic = clean_data(path)
    
    ## Gets all the unique API's in the data structure
    api_list_inter, app_list = unique_api_apps(apps_dic)
    
    
    ## Creates an intermediate A structure to find the count of each API
    print('creating intermediate A structure ')
    print('------------------------------------')
    a_matrix_inter = create_a_matrix\
    (app_list,api_list_inter, apps_dic)
    print('------------------------------------')
    
    ## Gets the index of all API's that occur less in less then n apps
    extra_api_list = get_index_of_api\
    (a_matrix_inter,api_list_inter,2)
    
     ## removes all the API's from the 3 data structures
    apps_dic,code_block_dic,package_dic = remove_apis\
    (extra_api_list,apps_dic,code_block_dic,package_dic)
    
    ## Gets the new list of unique API's
    api_list, app_list = unique_api_apps(apps_dic)

    ## Saves these datastructures again 
    save_structures(apps_dic,code_block_dic,package_dic,name_path )
    
    ## Saves unique api_list
    api_path = name_path[0] + '/processed/unique_api.text'
    with open(api_path, "wb") as fp: 
        pickle.dump(api_list, fp)
        
    
    ## Creates A matrix
    a_matrix = create_a_matrix(app_list,api_list,apps_dic)
    print('------------------------------------')
    ## Creatres B matrix
    b_matrix = create_b_matrix(code_block_dic,api_list,)
    print('------------------------------------')

    ## Creates P matrix 
    p_matrix = create_p_matrix(package_dic,api_list)
    print('------------------------------------')

    ## Saves all the 3 matrices 
    name_list = [name_path[0], 'a_matrix','b_matrix','p_matrix']
    save_features(a_matrix,b_matrix,p_matrix, name_list)


    ## Gets path to all benign apps
    test_benign_paths =  benign_paths[2:]

    ## Gets path to all malware apps
    malware_apps = []
    for i in malware_path:
        if i.split('/')[-1] not in app_list:
            malware_apps.append(i)

    malware_test_paths = malware_apps[2:4]

    ## Gets all the paths 
    
    test_paths = test_benign_paths + malware_test_paths

    ## Creates structure for the test set 
    print('creating data structure for test set')
    test_apps_dic = get_data_test(test_paths)
    print('------------------------------------')

    ## saves the new test structure created 
    test_name_list = [name_path[0], 'test_app_api.json']
    test_save_structures(test_apps_dic, test_name_list)
    
    # gets list of app names
    app_list_test = list(test_apps_dic.keys())
    
    ## Creates the A matrix for the test set 
    a_test_matrix = create_a_matrix_test(app_list_test,api_list,test_apps_dic)
    
    scores_dic = {}

    #Initilaze our linear SVC model
    clf = LinearSVC(max_iter = 10000)
    
    #loop through all the diffrent kernels
    kernel_list = ['A.A^T','A.B.A^T', 'A.P.A^T','A.B.P.A^T']
    
    for i,kernel in enumerate(kernel_list):
        if i == 0:
            train_kernel_product = aa_kernel(a_matrix,a_matrix)
            test_kernel_product = aa_kernel(a_test_matrix,a_matrix)
        elif i ==1:
            kernel_product = ab_or_p_kernel(a_matrix,a_matrix,b_matrix)
            test_kernel_product = ab_or_p_kernel(a_test_matrix,a_matrix,b_matrix)
        elif i == 2:
            kernel_product = ab_or_p_kernel(a_matrix,a_matrix,p_matrix)
            test_kernel_product = ab_or_p_kernel(a_test_matrix,a_matrix,p_matrix)
        else:
            kernel_product = apbpa_kernel(a_matrix, a_matrix,b_matrix,p_matrix)
            test_kernel_product = apbpa_kernel(a_test_matrix, a_matrix,b_matrix,p_matrix)
          
        df_train =create_df(train_kernel_product,benign_paths,app_list)
        
        df_test_aa  = create_df(test_kernel_product,test_benign_paths,app_list_test)
        
        scores_dic[kernel], test_df = run_model(df_train,df_test_aa, clf)
        
        print('for kernel '+ kernel + ' accuracy')
        print('\n')
        print(scores_dic[kernel])
        print('------------------------------------')
        print('\n')
        
    scores_df = pd.DataFrame(scores_dic)
    scores_df = scores_df.T
    print('saving accuray of model to results/'+ name_path[4])
    #save it as a CSV 
    result_path = 'results/'
    if not os.path.isdir(result_path):
        os.mkdir(result_path)
    scrores_path = result_path + '/'+ name_path[4]
    scores_df.to_csv(scrores_path)
    
if __name__=='__main__':
    warnings.filterwarnings("ignore")
    if sys.argv[1] == 'test':
        with open('config/test-params.json') as file:
            cfg = json.load(file)
    else: 
        with open('config/params.json') as file:
            cfg = json.load(file)
        
    main_func(**cfg)


