# Malware-detection

Our goal for this project was to classify apps into Malware or Benign by analysing the relationships between the API’s in the app. We represent apps and its API’s as a structured heterogeneous network. We use the meta-paths between them to create adjacency matrix which is used to aggregate similarity. We then create multi-kernels and fit in a machine learning model which assigns the weight through learning and makes the prediction. We create our own dataset of Benign apps from the APKpure website and use the AMD malware dataset for the malware apps.

## Usage Instructions

In a terminal or command window, navigate to the top-level project directory `malware-detection/` and run

`python3 run.py test-set`

or

`python3 run.py`


* Instructions

`python3 run.py test-set` - Runs code on 20 benign and 20 malware apps.


`python3 run.py` - Runs project on 1000 benign and 1000 malware apps

## Output 

`data/apk`: Conatins all the downloaded APK files

`data/smali`: Conatins all the decomplied smali code

`data/processes/app_to_api.json`: structure to create A matrix

`data/processes/code_block.json`: structure to create B matrix

`data/processes/library_dic.json`: structure to create P matrix

`results/scores.csv`: Performace metrics of model on diffrent kernels


## Description of Contents

The project consists of these portions:
```
PROJECT

├── README.md
├── config
│   ├── data-params.json
|   └── test-params.json
|   └── env.json
├── data
│   ├── apk
│   ├── smalli
│   └── processes
│       ├── app_to_api.json
|       ├── code_block.json
|       └── libray_dic.json 
├── notebooks
│   └── feature_extract.ipynb
├── requirements.txt
├── run.py
├── src
|    ├──  __init__.py
|    ├── build_features.py
|    ├── make_dataset.py
|    ├── elt.py
|    └── model.py
``` 

### `src`

* `etl.py`: Library code that executes tasks useful for getting data.
* `make_dataset.PY`: Library code that excutes task useful to cleaning and building dataset
* `build_features.py`: Library code that excutes task to extract features from dataset
* `model.py`: Library code  that excutes task to create and test model.

### `config`

* `params.json`: Common parameters for getting data, serving as
  inputs to library code.
  
* `test-set.json`: parameters for running small process on small
  test data.


### `notebooks`

* Jupyter notebooks for *analyses*
  - notebooks are not for data processing; they should import code
    from `src`.




